from django.http import HttpResponse
from django.views.decorators.csrf import csrf_exempt
import logging
import json
import jieba
import html
import re
import pandas as pd
import time
import numpy as np
from xpinyin import Pinyin
import codecs


# jieba loading
user_dict = './dict/user_dict_v1017.txt'
jieba.initialize()
jieba.load_userdict(user_dict)

df_tag_lib = pd.read_csv('./dict/tag_lib.csv', delimiter=',', encoding='utf-8')


def pair_to_dict(df):
    pair_dict = {}
    for ind, (label, alias) in df.iterrows():
        pair_dict[alias] = label
    return pair_dict

def generate_dict(df, rec_field):
    pair_dict = {}
    df = df[df['rec_field']==rec_field][['id','name']]
    for ind, (id,name) in df.iterrows():
        pair_dict[name] = id
    return pair_dict


def to_term_weight_dict(list):

    mydict = {}
    values = []
    for term, df, value in list:
        values.append(float(value))
        mydict[term] = float(value)

    avg = np.mean(values)
    median = np.median(values)
    return mydict, avg, median

def to_co_show_dict(path):
    co_show_dict = {}
    co_show_dict_sum = {}
    with open(path, "r", encoding='utf-8') as f1:
        for line in f1:
            line = line.strip()
            tokens = line.split("\t")
            if len(tokens)!=5:continue
            key = tokens[0]
            wordline = tokens[4]
            sum = 0
            if key not in co_show_dict:
                co_show_dict[key] = {}
            for wordstr in wordline.split(" "):
                subkey = wordstr.split(":")[0]
                value = float(wordstr.split(":")[-1])

                sum +=value
                co_show_dict[key][subkey] = value
            co_show_dict_sum[key] = sum
    return co_show_dict, co_show_dict_sum




dance_tag_dict = generate_dict(df_tag_lib,'content_dance')
teacher_tag_dict = generate_dict(df_tag_lib,'content_teacher')
tag_tag_dict = generate_dict(df_tag_lib,'content_tag')

mp3_dict = set([line.strip() for line in open("./dict/songs_dict", 'r', encoding='utf-8') if not line.startswith("#")])
term_weight_list = [ line.strip().split('\t') for line in open("./dict/term_weight", 'r', encoding='utf-8')]
co_show_path =  './dict/out_segmentv2.co_show'
# weight term
term_weight_dict, avg, median = to_term_weight_dict(term_weight_list)
co_show_dict, co_show_dict_sum = to_co_show_dict(co_show_path)
teacher_pair = pd.read_csv('./dict/content_teacher_pair.csv', delimiter=',', encoding='utf-8')
tag_pair = pd.read_csv('./dict/content_tag_pair.csv', delimiter=',', encoding='utf-8')
dance_pair = pd.read_csv('./dict/content_dance_pair.csv', delimiter=',', encoding='utf-8')
teacher_pair_dict = pair_to_dict(teacher_pair)
tag_pair_dict = pair_to_dict(tag_pair )
dance_pair_dict = pair_to_dict(dance_pair)




def get_mp3name(words, title):
    try:
        mp3_name = []
        if title in mp3_dict:
            mp3_name.append(title)
        for word in words:
            if word in mp3_dict:
                mp3_name.append(word)
        mp3_name = list(set(mp3_name))
        mp3_name.sort(reverse=True, key=len)
        return {'tagname': mp3_name[0], 'tagvalue': 1.0, 'tagid': 0}
    except:
        return {}


def get_tagname_tagid(words, df_pair, df_tag_lib, content_name):
    try:
        tag = []
        for word in words:
            df_label = df_pair[df_pair.alias == word][['label']]
            df_tag = df_tag_lib[(df_tag_lib.rec_field == content_name) & (df_tag_lib.name == word)][['id']]
            if not df_label.empty:
                label_name = df_label.iat[0, 0]
                tag_id = df_tag_lib[(df_tag_lib.rec_field == content_name) & (df_tag_lib.name == label_name)][['id', 'name']].iat[0, 0]
                tag.append({'tagname': label_name, 'tagvalue': 1.0, 'tagid': int(tag_id)})
            elif not df_tag.empty:
                # logging.info(word + 'in the elif')
                tag_id = df_tag.iat[0, 0]
                tag.append({'tagname': word, 'tagvalue': 1.0, 'tagid': int(tag_id)})
            else:
                continue
        if len(tag) == 0:
            # logging.info(content_name +'is get taganmeid tag==0')
            return [{'tagname': 'unknown', 'tagvalue': 1.0, 'tagid': 0}]
        return tag
    except:
        logging.info(content_name + 'is get taganmeid run except')
        return [{}]


def get_tagname_from_tagid(content_teach_id, content_name, df_tag_lib):
    tag_name = ''
    content_teach_id = int(content_teach_id.strip())
    df_tag = df_tag_lib[(df_tag_lib.rec_field == content_name) & (df_tag_lib.id == content_teach_id)][['name']]
    if not df_tag.empty:
        tag_name = df_tag.iat[0, 0]
        return tag_name
    return tag_name

def create_struct_data(words,pair_dict,tag_dict):
    # try:
    tag = []
    for word in words:
        # 标准化
        if word in pair_dict:
            id = tag_dict[pair_dict[word]]
            tag.append({'tagname': word, 'tagvalue': 1.0, 'tagid': id})
        elif word in tag_dict:
            # logging.info(word + 'in the elif')
            id = tag_dict[word]
            tag.append({'tagname': word, 'tagvalue': 1.0, 'tagid': id})
        else:
            continue
    if len(tag) == 0:
        return [{'tagname': 'unknown', 'tagvalue': 1.0, 'tagid': 0}]
    return tag
    # except:
    #     logging.info('content_dance is get taganmeid run except')
    #     return [{}]

# content_dance
def dance_type(words, content_dance_id):
    return create_struct_data(words,dance_pair_dict,dance_tag_dict)[0]


#  content_teacher
def teacher_type(words, title):
    m_set = set(words)
    newwords = words
    for word in words:
        word2 = ''
        if word.startswith("广场舞") or word.endswith("广场舞"):
            word2 = word.replace("广场舞", "")
        if word2 != "" and word2 not in m_set:
            newwords = [word2] + newwords
            m_set.add(word2)
    return create_struct_data(newwords, teacher_pair_dict, teacher_tag_dict)[0]


# content_tag
def tags_type(words, content_dance_id):
    newwords = words
    #if content_dance_id.strip():
        #tag_name = get_tagname_from_tagid(content_dance_id, 'content_dance', df_tag_lib)
        #newwords #= [tag_name] + newwords
    return create_struct_data(newwords, tag_pair_dict, tag_tag_dict)


# jcx
# clearning query  ==>> Task 0.
def cleaning_query(raw_query):
    clean_query = html.unescape(raw_query.strip())
    clean_query = re.sub("[^a-zA-Z0-9\u4e00-\u9fa5]+", "", clean_query)
    clean_query = clean_query.lower()
    re.sub('\s', '', clean_query)
    return clean_query


# words segment  ==>> Task 1.
def words_segment(query, pku_cut=True, jieba_cut=True):
    text = {}
    if jieba_cut:
        jieba_seg_res1 = jieba.cut(query)
        # jieba_seg_res1 = " ".join(jieba_seg_res1)
        jieba_seg_res = jieba.cut_for_search(query)
        # jieba_seg_res = " ".join(jieba_seg_res)
        result = jieba.tokenize(query, mode='search')
        position = " ".join(["{}:{}:{}".format(tk[0], tk[1], tk[2]) for tk in result])
        text['jieba_jingzhun'] = jieba_seg_res1
        text['jieba'] = jieba_seg_res
        text['posi_query'] = position

    return text


# jcx


def termweight_func(query):

    ## 加入共现字典的termweight  计算 搜索模式

    wordlist3 = []
    for i, wordi in enumerate(query):
        subtokeni = wordi.split(":")
        if len(subtokeni) != 3: continue
        wordlist3.append(subtokeni)

    tmp_dict = {}
    for i, subtokeni in enumerate(wordlist3):

        wi = subtokeni[0]
        w_fromi = int(subtokeni[1])
        w_toi = int(subtokeni[2])
        for j, subtokenj in enumerate(wordlist3):
            if j > i:
                wj = subtokenj[0]
                w_fromj = int(subtokenj[1])
                w_toj = int(subtokenj[2])
                if w_fromi >= w_fromj and w_toi <= w_toj:

                    if wj in co_show_dict and wi in co_show_dict[wj]:
                        v2 = co_show_dict[wj][wi]

                        if wj not in tmp_dict:
                            tmp_dict[wj] = v2
                        else:
                            tmp_dict[wj] += v2
                        if wi not in tmp_dict:
                            tmp_dict[wi] = -v2
                        else:
                            tmp_dict[wi] += -v2
    min =0
    max = 0
    for w, value in tmp_dict.items():
        if value < min:
            min = value
        if value > max:
            max = value
    jiange = max-min +0.0001

    term_score = []
    sum2 = 0
    termweight = []
    sum = 0
    for w in wordlist3:
        w = w[0]
        if w in term_weight_dict:
            termweight.append((w, term_weight_dict[w]))
            sum += term_weight_dict[w]
    for (term, weight) in termweight:
        score = float(weight/sum)
        v2 = 0
        if term in tmp_dict:
            v2 = tmp_dict[term]
        score2 = score +score*float(v2)/jiange
        term_score.append((term,score2))
        sum2 +=score2
        #outline +=str(term) +"/"+ str(round(score,4))+" "


    #归一化
    outline2 = ""
    for (term, score) in term_score:
        score2 = float(score)/sum2
        outline2 += str(term) + "/" + str(round(score2, 4)) + " "
    return outline2





def process_query(title):

    content_dance_id = "0"
    content_tag = []
    content_dance = {}
    content_mp3 = {}
    content_teacher = {}
    content_team_name = {}
    segment = ""

    # add  childcategory_id = "0"
    # 判断title的异常处理
    if len(title.strip()) == 0:
        return content_tag, content_dance, content_mp3, content_teacher, content_team_name, segment
    title = cleaning_query(title)
    segments = words_segment(title)
    cutted_title = list(segments['jieba_jingzhun'])
    if len(cutted_title) == 0:
        return content_tag, content_dance, content_mp3, content_teacher, content_team_name, segment
    start = time.time()
    content_mp3 = get_mp3name(cutted_title, title)
    end = time.time()
    logging.info("content_mp3 consuming is {} ms".format((end - start)*1000))

    # get dance tag
    start = time.time()
    content_dance = dance_type(cutted_title, content_dance_id)
    end = time.time()
    logging.info("content_dance consuming is {} ms".format((end - start) * 1000))
    # get teacher tag
    start = time.time()
    content_teacher = teacher_type(cutted_title, title)
    end = time.time()
    logging.info("content_teacher consuming is {} ms".format((end - start) * 1000))
    # get content tags ,is a list
    start = time.time()
    content_tag = tags_type(cutted_title, content_dance_id)
    end = time.time()
    logging.info("content_tag consuming is {} ms".format((end - start) * 1000))

    sum_normal = sum( [ term_weight_dict[term]  if term in term_weight_dict else  avg  for term in cutted_title ] )
    weighted_cutted_title =  [ "{}/{}".format(term, term_weight_dict[term]/sum_normal ) if term in term_weight_dict else "{}/{}".format(term, avg/sum_normal ) for term in cutted_title]

    cutted_title_seach = list(segments['jieba'])
    sum_search = sum( [ term_weight_dict[term]  if term in term_weight_dict else  avg  for term in  cutted_title_seach] )
    weighted_cutted_title_search = [ "{}/{}".format(term, term_weight_dict[term]/sum_search ) if term in term_weight_dict else "{}/{}".format(term, avg/sum_search) for term in cutted_title_seach]

    query_with_posi = segments['posi_query'].split(' ')
    segment_better = termweight_func(query_with_posi)

    segment_def = " ".join(weighted_cutted_title)
    segment_seach = " ".join(weighted_cutted_title_search)

    return content_tag, content_dance, content_mp3, content_teacher, content_team_name, segment_def, segment_seach, segment_better



# 纠错部分

# load user confusion dict
def load_user_confusion(user_confusion_path, p, flag):
    confusion_right = {}
    confusion_wrong = {}
    confusion_set = set()
    confusion_pinyin_term = {}
    confusion_term_pinyin = {}
    with codecs.open(user_confusion_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('#'):
                continue
            info = line.split()
            if len(info) < 2:
                continue
            if len(info[1]) > 2:
                variant = info[0]
                origin = info[1]
                confusion_wrong[variant] = origin
                confusion_right[origin] = variant
                if flag:
                    confusion_set.add(info[0])
                    confusion_set.add(info[1])
    if flag:
        for term in confusion_set:
            term_pinyin = p.get_pinyin(term, splitter='')
            confusion_pinyin_term[term_pinyin] = term
            confusion_term_pinyin[term] = term_pinyin
    return confusion_wrong, confusion_right, confusion_pinyin_term, confusion_term_pinyin


def load_one_column(path):
    gt_set = set()
    with codecs.open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('#'):
                continue
            query = line.split()[0].strip()
            gt_set.add(query)
    return gt_set


def load_standard_dict(standard_dict_path, p):
    song_pinyin_term = {}
    song_term_pinyin = {}
    with codecs.open(standard_dict_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('#'):
                continue
            info = line.split()
            mp3name = info[0]
            mp3name_pinyin = p.get_pinyin(mp3name, splitter='')
            song_pinyin_term[mp3name_pinyin] = mp3name
            song_term_pinyin[mp3name] = mp3name_pinyin
    return song_pinyin_term, song_term_pinyin


# find and correct
def find_and_replace(merge_token, sentence):
    idx = sentence.find(merge_token)
    if idx > -1:
        corrected_index = idx
    else:
        corrected_index = -1
    return corrected_index


def replace_by_term_with_correct(original_term, correct_term):
    correct_word_pinyin = {}
    for word in correct_term:
        correct_word_pinyin[Pinyin().get_pinyin(word, splitter='')] = word
    for word_index, word in enumerate(original_term):
        original_term_pinyin = Pinyin().get_pinyin(word, splitter='')
        if original_term_pinyin in correct_word_pinyin:
            original_term = original_term[:word_index] + correct_word_pinyin[original_term_pinyin] + original_term[
                                                                                                     word_index + 1:]
    return original_term


def compare_pinyin(term, term_pinyin, corrected_sentence, confusion_pinyin_term, confusion_wrong, confusion_right,
                   standard_index, standard_length):
    confusion_term = confusion_pinyin_term[term_pinyin]
    if confusion_term in confusion_right:
        correct_term = confusion_term
    elif confusion_term in confusion_wrong:
        correct_term = confusion_wrong[confusion_term]
    else:
        return corrected_sentence
    corrected_index = find_and_replace(term, corrected_sentence)
    correct_term_length = len(term)
    # 开始比较下标，标准化的不会再被更改
    if (corrected_index > standard_index and corrected_index > standard_index + standard_length - 1) \
            or (corrected_index < standard_index and corrected_index + correct_term_length - 1 < standard_index) \
            or (
            corrected_index <= standard_index and corrected_index + correct_term_length >= standard_index + standard_length):
        corrected_sentence = corrected_sentence.replace(term, correct_term)
    return corrected_sentence, correct_term


def read_and_compare(sentence, confusion_wrong, confusion_right, confusion_pinyin_term,
                     confusion_term_pinyin, plus_confusion_wrong, plus_confusion_right, song_term_pinyin, gt_set,
                     song_type_set, p):
    gcw = u'广场舞'
    # compare confusion dict
    song_type_set.add(gcw)
    re_sentence = sentence
    type_index = -1
    replaced_type = ''
    for type in song_type_set:
        if sentence.startswith(type) or sentence.endswith(type):
            replaced_type = type
            re_sentence = sentence.replace(type, '')
            type_index = sentence.find(type)
    if re_sentence in gt_set:
        corrected_sentence = re_sentence
        return complete_query(type_index, replaced_type, corrected_sentence)
    if re_sentence in song_term_pinyin:
        corrected_sentence = re_sentence
        return complete_query(type_index, replaced_type, corrected_sentence)
    # elif re_sentence in plus_confusion_right:
    #     corrected_sentence = re_sentence
    #     return complete_query(type_index, replaced_type, corrected_sentence)
    # elif re_sentence in confusion_right:
    #     corrected_sentence = re_sentence
    #     return complete_query(type_index, replaced_type, corrected_sentence)
    elif re_sentence in song_type_set:
        corrected_sentence = re_sentence
        return complete_query(type_index, replaced_type, corrected_sentence)
    elif re_sentence in plus_confusion_wrong:
        corrected_sentence = plus_confusion_wrong[re_sentence]
        return complete_query(type_index, replaced_type, corrected_sentence)
    elif re_sentence in confusion_wrong:
        corrected_sentence = confusion_wrong[re_sentence]
        return complete_query(type_index, replaced_type, corrected_sentence)
    else:
        tokens = list(jieba.cut(re_sentence))
        corrected_sentence = re_sentence
        standard_index = -1
        standard_length = -1
        replace_token = ''
        for index, term in enumerate(tokens):
            if term in song_term_pinyin:
                standard_index = re_sentence.find(term)
                standard_length = len(term)
            if term in confusion_wrong:
                replace_token = term
                corrected_index = find_and_replace(term, re_sentence)
                correct_term_length = len(term)
                # 开始比较下标，标准化的不会再被更改
                if (
                        corrected_index > standard_index and corrected_index > standard_index + standard_length - 1) or (
                        corrected_index < standard_index and corrected_index + correct_term_length - 1 < standard_index):
                    correct_term = confusion_wrong[replace_token]
                    corrected_sentence = re_sentence.replace(replace_token, correct_term)
                    tokens[index] = replace_by_term_with_correct(term, correct_term)

        if len(tokens) > 1:
            for i in range(len(tokens) - 1):
                merge_token = (tokens[i] + tokens[i + 1])
                term_pinyin = p.get_pinyin(merge_token, splitter='')
                if term_pinyin in confusion_pinyin_term:
                    corrected_sentence, correct_term = compare_pinyin(merge_token, term_pinyin,
                                                                      corrected_sentence,
                                                                      confusion_pinyin_term,
                                                                      confusion_wrong, confusion_right,
                                                                      standard_index,
                                                                      standard_length)
                    tokens[i] = replace_by_term_with_correct(tokens[i], correct_term)
                    tokens[i + 1] = replace_by_term_with_correct(tokens[i + 1], correct_term)
                merge_token = (tokens[i] + tokens[i + 1])
                if merge_token in confusion_wrong and corrected_sentence.find(merge_token) > -1:
                    replace_token = merge_token
                    corrected_index1 = find_and_replace(merge_token, corrected_sentence)
                    corrected_length1 = len(merge_token)
                    if (
                            corrected_index1 > standard_index and corrected_index1 > standard_index + standard_length - 1) or (
                            corrected_index1 < standard_index and corrected_index1 + corrected_length1 - 1 < standard_index):
                        correct_term = confusion_wrong[replace_token]
                        corrected_sentence = corrected_sentence.replace(replace_token, correct_term)
        tokens = list(jieba.cut(corrected_sentence))
        if len(tokens) > 2:
            for i in range(len(tokens) - 2):
                merge_token2 = (tokens[i] + tokens[i + 1] + tokens[i + 2])
                term_pinyin = p.get_pinyin(merge_token2, splitter='')
                if term_pinyin in confusion_pinyin_term:
                    corrected_sentence, correct_term = compare_pinyin(merge_token2, term_pinyin,
                                                                      corrected_sentence,
                                                                      confusion_pinyin_term,
                                                                      confusion_wrong, confusion_right,
                                                                      standard_index, standard_length)
                    tokens[i] = replace_by_term_with_correct(tokens[i], correct_term)
                    tokens[i + 1] = replace_by_term_with_correct(tokens[i + 1], correct_term)
                    tokens[i + 2] = replace_by_term_with_correct(tokens[i + 2], correct_term)
                merge_token2 = (tokens[i] + tokens[i + 1] + tokens[i + 2])
                if merge_token2 in confusion_wrong and corrected_sentence.find(merge_token2) > -1:
                    replace_token = merge_token2
                    corrected_index2 = find_and_replace(merge_token2, corrected_sentence)
                    corrected_length2 = len(merge_token2)
                    if (
                            corrected_index2 > standard_index and corrected_index2 > standard_index + standard_length - 1) or (
                            corrected_index2 < standard_index and corrected_index2 + corrected_length2 - 1 < standard_index):
                        corrected_sentence = corrected_sentence.replace(replace_token,
                                                                        confusion_wrong[replace_token])

        return complete_query(type_index, replaced_type, corrected_sentence)

def complete_query(type_index,replaced_type,corrected_sentence):
    if type_index == 0:
        corrected_sentence = replaced_type + corrected_sentence
    elif type_index > 0:
        corrected_sentence = corrected_sentence + replaced_type
    return corrected_sentence

def my_correct_fun(query):
    # load user confusion dict
    # compare
    corrected_sentence = read_and_compare(query, confusion_wrong, confusion_right, confusion_pinyin_term,
                     confusion_term_pinyin, plus_confusion_wrong, plus_confusion_right, song_term_pinyin, gt_set,
                     song_type_set, p)
    return corrected_sentence

p = Pinyin()
user_confusion_path = './dict2/custom_confusion_v1030.txt'
standard_dict_path = './dict2/new_song_dict.txt'
plus_user_confusion_path = './dict2/plus_custom_confusion_v1104.txt'
ground_true_dict_path = './dict2/ground_true_dict_v1104.txt'
song_type_path = './dict2/new_category_dict.txt'
confusion_wrong, confusion_right, confusion_pinyin_term, confusion_term_pinyin = load_user_confusion(
    user_confusion_path, p, True)
# load standard dict
song_pinyin_term, song_term_pinyin = load_standard_dict(standard_dict_path, p)
plus_confusion_wrong, plus_confusion_right, plus_confusion_pinyin_term, plus_confusion_term_pinyin = load_user_confusion(
    plus_user_confusion_path, p, False)
gt_set = load_one_column(ground_true_dict_path)
song_type_set = load_one_column(song_type_path)
# 纠错部分
@csrf_exempt
def querytag(request):
    querytitle = ""
    start = time.time()

    if request.method == "POST":
        querytitle = request.POST.get('title', '')
    elif request.method == "GET":
        querytitle = request.GET.get('title', '')

    try:
        result = {}
        request_info = {}
        content = re.sub("[^a-zA-Z0-9\u4e00-\u9fa5]+", " ", querytitle)
        if len(content.strip())==0:
            result['code'] = 0
            responsejson = json.dumps({'tag': result}, ensure_ascii=False)
            return HttpResponse(responsejson)
        request_info['query'] = querytitle

        requestjson = json.dumps(request_info, ensure_ascii=False)
        logging.info("Request:" + requestjson)

        content_tag, content_dance, content_mp3, content_teacher, content_team_name, segment_def, segment_seach, segment_better = process_query(querytitle)

        ori = {}
        ori['ori_query'] = querytitle
        ori['content_tag'] = [dict(t) for t in {tuple(d.items()) for d in content_tag}]
        ori['content_dance'] = content_dance
        ori['content_mp3'] = content_mp3
        ori['content_teacher'] = content_teacher
        ori['content_team_name'] = content_team_name
        ori['segment_def'] = segment_def
        ori['segment_seach'] = segment_seach
        ori['segment_better'] = segment_better
        correct = {}
        start1 = time.time()
        querytitle2 = my_correct_fun(querytitle)
        end2 = time.time()
        abc = "time is {}".format(end2-start1)
        print(abc)
        if querytitle2 == querytitle:
            result['original'] = ori
            result['code'] = 1
        else:
            content_tag, content_dance, content_mp3, content_teacher, content_team_name, segment_def, segment_seach, segment_better = process_query(
                querytitle2)
            correct['cor_query'] = querytitle2
            correct['content_tag'] = [dict(t) for t in {tuple(d.items()) for d in content_tag}]
            correct['content_dance'] = content_dance
            correct['content_mp3'] = content_mp3
            correct['content_teacher'] = content_teacher
            correct['content_team_name'] = content_team_name
            correct['segment_def'] = segment_def
            correct['segment_seach'] = segment_seach
            correct['segment_better'] = segment_better
            result['original'] = ori
            result['correct'] = correct
            result['code'] = 1


        responsejson = json.dumps({'tag': result}, ensure_ascii=False)
        end = time.time()
        logging.info("Response:" + responsejson + 'the process time is ' + str(end - start))
        return HttpResponse(responsejson)
    except Exception as e:
        logging.error("querytag exception: " + e)
